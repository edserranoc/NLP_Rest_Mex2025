{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "200604e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from torch.utils.data import (DataLoader,      # library for data loading.\n",
    "                              Dataset)         # library for dataset.\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.pipelines.data_pipeline import DataPipeline\n",
    "from collections import Counter\n",
    "from src.pipelines.dataset import collate_fn_hierarchical\n",
    "from src.train.train import compute_class_weights, MultiTaskTrainer\n",
    "from src.models.hierarchical_model import HierarchicalMultiTaskModel\n",
    "from src.inference.predict import predict_rest_mex_test\n",
    "\n",
    "np.random.seed(0)                              # seed for reproducibility.\n",
    "random.seed(0)                                 # seed for reproducibility.\n",
    "torch.manual_seed(0)                           # seed for reproducibility.\n",
    "torch.backends.cudnn.benchmark = False         # reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e601026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc1fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len = 243 (percentil 99)\n"
     ]
    }
   ],
   "source": [
    "pipeline = DataPipeline(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c2416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shape : torch.Size([7, 2, 243])\n",
      "Labels shape      : torch.Size([7, 2])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    pipeline.train_dataset,\n",
    "    batch_size = 8,  # <- 8 pueblos por batch\n",
    "    shuffle    = False,\n",
    "    collate_fn = collate_fn_hierarchical\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    pipeline.val_dataset,\n",
    "    batch_size = 8,\n",
    "    shuffle    = False,\n",
    "    collate_fn = collate_fn_hierarchical\n",
    ")\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "print(\"Train batch shape :\", batch[0].shape)\n",
    "print(\"Labels shape      :\", batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ce7bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity Counter: Counter({5: 136561, 4: 45034, 3: 15519, 2: 5496, 1: 5441})\n",
      "Town Counter: Counter({'Tulum': 45345, 'Isla_Mujeres': 29826, 'San_Cristobal_de_las_Casas': 13060, 'Valladolid': 11637, 'Bacalar': 10822, 'Palenque': 9512, 'Sayulita': 7337, 'Valle_de_Bravo': 5959, 'Teotihuacan': 5810, 'Loreto': 5525, 'TodosSantos': 4600, 'Patzcuaro': 4454, 'Taxco': 4201, 'Tlaquepaque': 4041, 'Ajijic': 3752, 'Tequisquiapan': 3627, 'Metepec': 3532, 'Tepoztlan': 3445, 'Cholula': 2790, 'Tequila': 2650, 'Orizaba': 2521, 'Izamal': 2041, 'Creel': 1786, 'Ixtapan_de_la_Sal': 1696, 'Zacatlan': 1602, 'Huasca_de_Ocampo': 1509, 'Mazunte': 1466, 'Xilitla': 1458, 'Atlixco': 1444, 'Malinalco': 1429, 'Bernal': 1252, 'Tepotzotlan': 1013, 'Cuetzalan': 996, 'Chiapa_de_Corzo': 960, 'Parras': 953, 'Dolores_Hidalgo': 909, 'Coatepec': 818, 'Cuatro_Cienegas': 788, 'Real_de_Catorce': 760, 'Tapalpa': 725})\n",
      "Type Counter: Counter({'Restaurant': 86720, 'Attractive': 69921, 'Hotel': 51410})\n"
     ]
    }
   ],
   "source": [
    "counter_polarity = Counter([int(p[0]) for p in pipeline.labels])\n",
    "counter_town = Counter([p[1] for p in pipeline.labels])\n",
    "counter_type = Counter([p[2] for p in pipeline.labels])\n",
    "\n",
    "print(\"Polarity Counter:\", counter_polarity)\n",
    "print(\"Town Counter:\", counter_town)\n",
    "print(\"Type Counter:\", counter_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc23bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = pipeline.emb_mat.clone().detach().to(dtype = torch.float, device = device)\n",
    "modelHierarchical = HierarchicalMultiTaskModel(\n",
    "    vocab_size       = pipeline.emb_mat.shape[0],\n",
    "    embed_dim        = embedding_matrix.shape[1],\n",
    "    hidden_size      = 512,\n",
    "    num_polarities   = 5,\n",
    "    num_types        = 3,\n",
    "    num_towns        = 40,\n",
    "    embedding_matrix = embedding_matrix\n",
    ").to(device)\n",
    "\n",
    "trainerHierarchical = MultiTaskTrainer(\n",
    "    model            = modelHierarchical,\n",
    "    epochs           = 20,\n",
    "    train_dataset    = pipeline.train_dataset,\n",
    "    train_dataloader = train_dataloader,\n",
    "    val_dataloader   = val_dataloader,\n",
    "    device           = device,\n",
    "    lr               = 1e-3,\n",
    "    patience         = 8,\n",
    "    weight_decay     = 1e-4,\n",
    "    type2id          = pipeline.type2id,\n",
    "    town2id          = pipeline.town2id,\n",
    "    lambdas          = (5/48, 40/48, 3/48),\n",
    "    polarity_counter = counter_polarity,\n",
    "    town_counter     = counter_town,\n",
    "    type_counter     = counter_type,\n",
    "    checkpoint_filename = 'checkpoint_hierarchical.pth',\n",
    "    best_model_filename = 'best_model_hierarchical.pth',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f0ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainerHierarchical.train()\n",
    "#trainerHierarchical.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db9f03c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado desde best_model_hierarchical.pth\n"
     ]
    }
   ],
   "source": [
    "trainerHierarchical.load_model('best_model_hierarchical.pth')  # carga el mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fc55165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Test Set: 100%|\u001b[36m██████████\u001b[0m| 1394/1394 [02:25<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo generado: final.txt\n"
     ]
    }
   ],
   "source": [
    "predict_rest_mex_test(\n",
    "    model           = modelHierarchical,\n",
    "    pipeline        = pipeline,\n",
    "    output_filename = 'final.txt',\n",
    "    device          = device,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
